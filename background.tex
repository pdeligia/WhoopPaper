\subsection{Concurrency in the Linux Kernel}
\label{bg:concurrency}

\ADComment{I believe that \emph{responsiveness} is a key motivator for concurrency in device drivers: even if there is only a single core, we may wish for driver entry points of distinct processes to run concurrently so that no single process hogs the core.  Can you please consider weaving this into what follows?}

Nowadays, multicore architectures have become mainstream, leading to an ever-increasing demand for concurrency in operating systems. Modern Linux kernel distributions address this demand by providing multiple sources of concurrency~\cite{corbet2005linux}: the kernel can invoke an arbitrary number of entry points from the same driver concurrently; a running driver process can block and be replaced by another process in the same driver; hardware interrupts can be handled concurrently; delayed code execution is the norm; and the user can insert or remove hardware components without rebooting the kernel (known as hot-plugging). All these possibilities can easily lead to serious concurrency issues, such as \emph{data races}, which can be defined as follows:

\begin{definition}
\label{definition:datarace}
A data race occurs when two distinct threads access a shared memory location, at least one of the accesses modifies the location, at least one of the accesses is non-atomic, and there is no mechanism in place to prevent these accesses from being simultaneous.
\end{definition}

\ADComment{In the definition, I added the part about at least one of the accesses being non-atomic.  I believe this is important in drivers, since there are cases where people use atomics.  Could you somewhere briefly acknowledge, referring back to Definition~\ref{definition:datarace}, that we treat atomics soundly in whoop, in the sense that we do not regard them as providing any protection between threads?}

\ADComment{It would be much more compelling, even if it takes more space, if you could find a small snippet from a real driver such that there is a data race say on a field of a struct.  Could you replace the contrived example with such an example?}  Example~\ref{fig:data_race_example} presents a simple data race between two entry points of a Linux driver. The resource \texttt{dev->resource} is shared between the two entry points \texttt{ep1} and \texttt{ep2}. Entry point \texttt{ep1} writes the value 5 to \texttt{dev->resource}, and entry point \texttt{ep2} writes the value 3 to \texttt{dev->resource} if the value of \texttt{dev->resource} is not 5. A data race can occur if \texttt{ep1} and \texttt{ep2} run concurrently: the read and write accesses to the shared resource may execute in arbitrary order leading to nondeterministic behavior.  \ADComment{If you stick with this example, it would be worth pointing out that a write-write race is also possible.}

\begin{lstlisting}[caption = Simple data race in a Linux driver \ADComment{I think the caption is misleading, since this is clearly not a driver}, label = fig:data_race_example]
static void ep1 (struct shared *dev) {
  dev->resource = 5;
}

static void ep2 (struct shared *dev) {
  if (dev->resource != 5)
    dev->resource = 3;
}
\end{lstlisting}

The most common technique for eliminating data races is using a \emph{locking} mechanism. Locking a set of program statements that access a shared resource creates a \emph{critical section}, i.e. source code that cannot be executed by more than one thread simultaneously. Example~\ref{fig:lock_example} shows how to use a lock to eliminate the data race in Example~\ref{fig:data_race_example}.

\begin{lstlisting}[caption = Using locks to eliminate the data race, label = fig:lock_example]
static void ep1 (struct shared *dev) {
  mutex_lock(&dev->lock);
  dev->resource = 5;
  mutex_unlock(&dev->lock);
}

static void ep2 (struct shared *dev) {
  mutex_lock(&dev->lock);
  if (dev->resource != 5)
    dev->resource = 3;
  mutex_unlock(&dev->lock);
}
\end{lstlisting}

Lock-based synchronization is a powerful tool for preventing data races in drivers, but careless use of locks has multiple pitfalls~\cite{sutter2005software}. Coarse-grained locking can \ADComment{I removed the word ``severely''.  My PhD supervisor always advised me to avoid using words that are subjective.} hurt performance, because it limits the opportunity for concurrency. On the other hand, fine-grained locking can easily lead to deadlocks.  \ADComment{Removed description of deadlock, as it is well known.}
\ADComment{Suggestion: expand the following a little to say what one of the lock-free synchronization methods in Linux is.  Perhaps take this opportunity to refer back to the stuff about ``atomic'' I added in the data race definition.}  Although the Linux kernel provides sophisticated lock-free synchronization mechanisms~\cite{corbet2005linux}, in this work we focus on locks.  \ADComment{Can we justify the focus on locks a bit more?  E.g., are you able to survey, via grepping, what percentage of Linux drivers make use of locks (likely 100\%?) vs.\ what percentage also make use of lock-free mechanisms?}

\subsection{Reasoning about Thread Interleavings}
\label{bg:happensbefore}

\ADComment{I am unsure as to whether we need this background, but I'm undecided as I'm still getting on top of the rest of the material.}

A fundamental concept in concurrency analysis is Lamport's \emph{happens-before} relation~\cite{lamport1978time}, which denotes a partial-order between all events during the execution of a concurrent program. Happens-before can be defined as follows:

\begin{definition}
\label{definition:datarace}
Let $E_1$ and $E_2$ be two events during a program's concurrent execution. If $E_1$ and $E_2$ are in the same thread and $E_1$ occurs before $E_2$, or if $E_1$ and $E_2$ are in different threads and there is a synchronization mechanism (e.g. locking) that prevents a thread schedule in which $E_2$ occurs before $E_1$, then $E_1 \rightarrow E_2$, where the symbol $\rightarrow$ denotes the happens-before relation.
\end{definition}

Happens-before is transitive, i.e. for any three events $E_1$, $E_2$ and $E_3$, if $E_1 \rightarrow E_2$ and $E_2 \rightarrow E_3$, then $E_1 \rightarrow E_3$. If two events $E_1$ and $E_2$ occur in different threads, and neither $E_1 \rightarrow E_2$, nor $E_2 \rightarrow E_1$ holds, then $E_1$ and $E_2$ happen concurrently, which indicates a data race if the two events access the same shared resource and at least one of the accesses is a modifier.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\linewidth]{img/happens_before.pdf}
\caption{Applying happens-before in two concurrently running threads}
\label{fig:happens_before}
\end{figure}

Figure~\ref{fig:happens_before} shows an example of applying happens-before reasoning in two concurrently running entry points. Each of the three statements $\{A, B, C\}$ in thread 1 is executed before the next one, and thus all of them are ordered by the happens-before relation. The same applies for each of the four statements $\{D, E, F, G\}$ in thread 2. Statement $C$ in thread 1 releases the lock, and subsequently allows $D$ in thread 2 to acquire the same lock. Thus, $C \rightarrow D$. This means that for this specific thread interleaving the set of statements $\{A, B, C\}$ happens before the set of statements $\{D, E, F, G\}$.

The above example also showcases the main limitation of happens-before. If the technique explores \emph{only} this specific thread interleaving, it will miss a potential data race between statements $B$ and $G$, because $B \rightarrow G$ in this specific schedule. Thus, a tool based on happens-before requires a scheduler that produces as many different thread interleavings as possible to increase execution path coverage~\cite{savage1997eraser}. Achieving full coverage with tools based on happens-before is infeasible though, because of the exponential number of possible thread interleavings in realistic concurrent programs. Furthermore, attempting to explore a large number of thread schedules quickly leads to scalability issues~\cite{musuvathi2008finding}, a problem known as state space explosion. Thus, previous work based on happens-before typically explore paths under a certain bound, such as the number of allowed context switches~\cite{qadeer2004kiss}.

\subsection{Reasoning about Locksets}
\label{bg:lockset}

An alternative approach to happens-before, known as \emph{lockset analysis}, resolves around reasoning about the locking behavior of concurrent programs. Lockset analysis was proposed in the context of Eraser~\cite{savage1997eraser}, a dynamic data race detector that tracks the set of locks that \emph{consistently} protect a memory location during program execution. If that lockset ever becomes empty, the analysis reports a potential data race on that memory location. \ADComment{This could be better explained, I think.} This is because an inconsistent lockset suggests that a memory location \emph{may} be accessed simultaneously by two or more threads.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\linewidth]{img/lockset.pdf}
\caption{Applying lockset analysis on a thread of a concurrent program}
\label{fig:locksets}
\end{figure}

\ADComment{What is missing from the explanation, and from the example you give, is the idea that with a dynamic approach, you run the program and a thread operates in a truly concurrent environment.  You thus only get to see what the thread did on the particular schedule that was followed.  I also think you should use a two-threaded example, instead of a one-threaded example, to show that although thread $T$ might consistently use mutex $M$ to protect variable $A$, this is no good if thread $U$ accesses variable $A$ without holding $M$.}  \ADComment{If you use multiple letters in math mode, you should use ``mathit'' to get them typeset properly.  E.g., you should write $\mathit{CLS}_T$, not $CLS_T$, and $\mathit{LS}_v$, not $LS_v$.  Can you please address this throughout the paper?  It can be cumbersome to write, making it worth thinking about adding macros.}

Lockset analysis for a concurrent program starts by creating a \emph{current} lockset, $CLS_T$, for each thread $T$ of the program, and a lockset, $LS_v$, for each shared variable $v$ used in the program.
Initially, $CLS_T$ is empty for every thread $T$, because the threads do not hold any locks on program start.
The lockset $LS_v$ for each variable $v$ is initialised to the set of all locks manipulated by the program,
because initially each access to $v$ has (vacuously) been protected by every lock.
The program is executed as usual (with threads scheduled according to the OS scheduler), except that
instrumentation is added to update locksets as follows:
%
\begin{enumerate}
\item After each \emph{lock} and \emph{unlock} operation by thread $T$, $CLS_T$ is updated to reflect the locks currently held by $T$.
\item When thread $T$ accesses shared variable $v$, any locks that are not common to $LS_v$ and $CLS_T$ are removed from $LS_v$.
If $LS_v$ becomes empty as a result, a warning is issued that the access to $v$ may be unprotected.
\end{enumerate}

In the example of Figure~\ref{fig:locksets}, we analyze only one thread $T$ and one shared variable $A$ and thus there are two locksets: the current lockset for $T$ ($CLS_T$) and the lockset for $A$ ($LS_A$). 

Figure~\ref{fig:locksets} shows an example of applying lockset analysis on a thread of a concurrent program.
\ADComment{I folded some of the discussion of the example into the above more general description of locksets.  Assuming you do produce a two-threaded example, please put in a brief explanation of it.}

Lockset analysis avoids reasoning about arbitrary thread interleavings \ADComment{is this true of standard lockset analysis?  With Eraser, a single interleaving would indeed provide a lot of information about races, but it would still be necessary to explore lots of interleavings to get high coverage, since the program behaviour may be schedule-dependent}, and thus has the potential to scale well in realistic concurrent programs. The technique, though, suffers from imprecision (i.e. can report many false bugs), because a violation of the locking discipline does not always correspond to a real data race~\cite{savage1997eraser, pozniansky2003efficient, o2003hybrid, elmas2007goldilocks, flanagan2009fasttrack}. Furthermore, as a classic dynamic analyzer, Eraser's bug-finding ability is limited to the execution paths that the tool explores. \ADComment{Perhaps re-phrase this to say that some existing techniques (cite them) have explored the idea of static lock set analysis, based on dataflow analysis, and that we also present a static lockset analysis method, that involves generating verification conditions to be discharged to a theorem prover} To counter these limitations, we apply the idea of Eraser's lockset analysis in a static verification context.
